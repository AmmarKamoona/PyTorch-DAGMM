{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from train import TrainerDAGMM\n",
    "from test import eval\n",
    "from preprocess import get_KDDCup99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1024/317394: [>...............................] - ETA 0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/PyTorch-DAGMM/forward_step.py:79: UserWarning: torch.potrf is deprecated in favour of torch.cholesky and will be removed in the next release. Please use torch.cholesky instead and note that the :attr:`upper` argument in torch.cholesky defaults to ``False``.\n",
      "  l = torch.potrf(a, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317394/317394: [===============================>] - ETA 0.7sss\n",
      "Training DAGMM... Epoch: 0, Loss: 957.777\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 1, Loss: 957.343\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 2, Loss: 957.518\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 3, Loss: 959.338\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 4, Loss: 958.149\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 5, Loss: 957.513\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 6, Loss: 958.050\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 7, Loss: 957.579\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 8, Loss: 958.355\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 9, Loss: 957.629\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 10, Loss: 957.562\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 11, Loss: 958.677\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 12, Loss: 958.291\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 13, Loss: 956.736\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 14, Loss: 958.068\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 15, Loss: 958.057\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 16, Loss: 958.733\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 17, Loss: 958.580\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 18, Loss: 957.523\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 19, Loss: 957.828\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 20, Loss: 958.043\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 21, Loss: 958.407\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 22, Loss: 958.068\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 23, Loss: 959.164\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 24, Loss: 959.067\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 25, Loss: 957.691\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 26, Loss: 957.517\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 27, Loss: 956.575\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 28, Loss: 958.557\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 29, Loss: 957.190\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 30, Loss: 958.812\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 31, Loss: 957.474\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 32, Loss: 957.220\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 33, Loss: 957.653\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 34, Loss: 957.771\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 35, Loss: 958.155\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 36, Loss: 958.378\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 37, Loss: 959.313\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 38, Loss: 958.040\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 39, Loss: 959.391\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 40, Loss: 957.566\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 41, Loss: 958.018\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 42, Loss: 958.255\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 43, Loss: 957.385\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 44, Loss: 958.382\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 45, Loss: 957.701\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 46, Loss: 957.971\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 47, Loss: 958.104\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 48, Loss: 957.882\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 49, Loss: 957.383\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 50, Loss: 958.200\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 51, Loss: 957.916\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 52, Loss: 958.079\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 53, Loss: 958.322\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 54, Loss: 957.929\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 55, Loss: 958.424\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 56, Loss: 957.534\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 57, Loss: 957.396\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 58, Loss: 957.619\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 59, Loss: 957.418\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 60, Loss: 957.270\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 61, Loss: 958.859\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 62, Loss: 957.288\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 63, Loss: 958.500\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 64, Loss: 957.857\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 65, Loss: 959.012\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 66, Loss: 957.758\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 67, Loss: 958.868\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 68, Loss: 957.139\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 69, Loss: 957.221\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 70, Loss: 958.794\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 71, Loss: 958.418\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 72, Loss: 957.862\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 73, Loss: 958.080\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 74, Loss: 956.826\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 75, Loss: 957.559\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 76, Loss: 957.953\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 77, Loss: 957.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 78, Loss: 958.971\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 79, Loss: 957.307\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 80, Loss: 958.984\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 81, Loss: 957.175\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 82, Loss: 957.562\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 83, Loss: 958.567\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 84, Loss: 957.534\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 85, Loss: 958.320\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 86, Loss: 959.266\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 87, Loss: 958.203\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 88, Loss: 957.162\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 89, Loss: 956.969\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 90, Loss: 958.088\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 91, Loss: 958.324\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 92, Loss: 957.390\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 93, Loss: 957.557\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 94, Loss: 959.029\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 95, Loss: 957.245\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 96, Loss: 957.624\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 97, Loss: 958.659\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 98, Loss: 958.461\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 99, Loss: 957.711\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 100, Loss: 957.826\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 101, Loss: 957.970\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 102, Loss: 958.933\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 103, Loss: 957.482\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 104, Loss: 958.389\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 105, Loss: 957.878\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 106, Loss: 957.919\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 107, Loss: 955.890\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 108, Loss: 957.623\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 109, Loss: 957.208\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 110, Loss: 958.782\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 111, Loss: 958.490\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 112, Loss: 957.151\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 113, Loss: 958.659\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 114, Loss: 958.757\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 115, Loss: 957.645\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 116, Loss: 957.910\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 117, Loss: 958.163\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 118, Loss: 957.476\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 119, Loss: 959.607\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 120, Loss: 958.669\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 121, Loss: 957.803\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 122, Loss: 958.150\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 123, Loss: 957.826\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 124, Loss: 957.966\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 125, Loss: 957.507\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 126, Loss: 957.640\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 127, Loss: 957.387\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 128, Loss: 957.492\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 129, Loss: 958.306\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 130, Loss: 957.681\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 131, Loss: 958.379\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 132, Loss: 958.696\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 133, Loss: 956.922\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 134, Loss: 958.077\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 135, Loss: 957.589\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 136, Loss: 957.205\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 137, Loss: 957.858\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 138, Loss: 958.947\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 139, Loss: 958.096\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 140, Loss: 957.976\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 141, Loss: 957.010\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 142, Loss: 957.844\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 143, Loss: 958.273\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 144, Loss: 957.915\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 145, Loss: 958.885\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 146, Loss: 958.391\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 147, Loss: 958.318\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 148, Loss: 958.147\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 149, Loss: 957.783\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 150, Loss: 957.075\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 151, Loss: 958.405\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 152, Loss: 957.955\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 153, Loss: 958.214\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 154, Loss: 958.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 155, Loss: 958.908\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 156, Loss: 957.085\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 157, Loss: 957.815\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 158, Loss: 957.507\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 159, Loss: 958.043\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 160, Loss: 956.601\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 161, Loss: 957.922\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 162, Loss: 957.140\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 163, Loss: 957.383\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 164, Loss: 957.625\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 165, Loss: 957.867\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 166, Loss: 957.426\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 167, Loss: 958.690\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 168, Loss: 957.455\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 169, Loss: 957.874\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 170, Loss: 956.645\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 171, Loss: 956.586\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 172, Loss: 957.750\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 173, Loss: 957.137\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 174, Loss: 958.217\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 175, Loss: 957.619\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 176, Loss: 956.990\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 177, Loss: 958.545\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 178, Loss: 957.264\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 179, Loss: 958.998\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 180, Loss: 958.504\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 181, Loss: 958.123\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 182, Loss: 958.153\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 183, Loss: 958.890\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 184, Loss: 957.686\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 185, Loss: 957.680\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 186, Loss: 957.517\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 187, Loss: 957.981\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 188, Loss: 958.077\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 189, Loss: 957.182\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 190, Loss: 957.214\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 191, Loss: 958.163\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 192, Loss: 958.349\n",
      "317394/317394: [===============================>] - ETA 0.0ss\n",
      "Training DAGMM... Epoch: 193, Loss: 958.616\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 194, Loss: 957.794\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 195, Loss: 958.378\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 196, Loss: 957.878\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 197, Loss: 959.363\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 198, Loss: 956.913\n",
      "317394/317394: [===============================>] - ETA 0.1ss\n",
      "Training DAGMM... Epoch: 199, Loss: 957.276\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    num_epochs=200\n",
    "    patience=50\n",
    "    lr=1e-4\n",
    "    lr_milestones=[50]\n",
    "    batch_size=1024\n",
    "    latent_dim=1\n",
    "    n_gmm=4\n",
    "    lambda_energy=0.1\n",
    "    lambda_cov=0.005\n",
    "    \n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = get_KDDCup99(args)\n",
    "\n",
    "dagmm = TrainerDAGMM(args, data, device)\n",
    "dagmm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/PyTorch-DAGMM/forward_step.py:79: UserWarning: torch.potrf is deprecated in favour of torch.cholesky and will be removed in the next release. Please use torch.cholesky instead and note that the :attr:`upper` argument in torch.cholesky defaults to ``False``.\n",
      "  l = torch.potrf(a, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.7825, Recall : 0.7509, F-score : 0.7664\n",
      "ROC AUC score: 0.952\n"
     ]
    }
   ],
   "source": [
    "from test import eval\n",
    "\n",
    "labels, scores = eval(dagmm.model, data, device, args.n_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "scores_in = scores[np.where(labels==0)[0]]\n",
    "scores_out = scores[np.where(labels==1)[0]]\n",
    "\n",
    "\n",
    "in_ = pd.DataFrame(scores_in, columns=['Inlier'])\n",
    "out_ = pd.DataFrame(scores_out, columns=['Outlier'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "in_.plot.kde(ax=ax, legend=True, title='Outliers vs Inliers (Deep SVDD)')\n",
    "out_.plot.kde(ax=ax, legend=True)\n",
    "#plt.xlim(-0.05, 0.08)\n",
    "ax.grid(axis='x')\n",
    "ax.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
